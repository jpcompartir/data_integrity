---
title: "Internal data collection"
format:
  html:
    toc-location: left
    toc-depth: 4
    theme: lux
    highlight-style: espresso
execute:
  echo: false
  message: false
  warning: false
---

```{r}
library(tidyverse)
```

# Schema

id | text | label | label_text | source
 
# Publicly Available

Kaggle dataset takes from [Spam Assassin](https://spamassassin.apache.org/old/publiccorpus/) which was created in the early 2000's, so we could do with something more modern...

The Kaggle Dataset has some pre-processing already baked in e.g. numbers -> NUMBER.
```{r}
kaggle_spam <- read_csv("~/Downloads/spam_or_not_spam.csv") %>%
  filter(!is.na(email))
```

Dataset is imbalanced, 5 -> 1 in terms of not_spam vs spam. 
```{r}
kaggle_spam %>%
  count(label)
```

Re-format and add an id column
```{r}
kaggle_spam <- kaggle_spam %>%
  rename(text = email) %>%
  mutate(source = "kaggle_spam",
         label_text = case_match(label,
                            1 ~ "spam",
                            0 ~ "not_spam"),
         id = paste0("kaggle_", row_number())) %>%
  relocate(id, text, label, label_text, source)

# write_csv(kaggle_spam, here("data/corpus/kaggle_spam.csv"))
```

# Internal

```{r}
ds_pj <- "~/Google Drive/My Drive/data_science_project_work/microsoft/project_work/"

data_files <- list.files(ds_pj, 
                         pattern = "*.csv|.xlsx", 
                         recursive = TRUE, 
                         full.names = TRUE)


```

# Synthetic Data

Spam definition prompt

Generations:
Topics -> 10 given by us
Subtopics -> 10 generated by each LLM for each topic

Prompt to write a document for each topic/subtopic/spam vs not spam 

Brands -> 10 most common per subtopic